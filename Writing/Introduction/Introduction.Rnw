<<set-parent1, echo=FALSE, cache=FALSE>>=
knitr::set_parent(parent = "../Main/Main.Rnw")
@

\chapter{Introduction}
\label{ch:intro}
In today's society, one of the greatest benefits is the ease of access to collection and dissemination of information. In particular with vast technological advancement in personal electronic devices, such as cell phones and tablets, one can \emph{remotely} and \emph{wirelessly} share information from any major parts of the world. Search engine tools provide answers for most of our curiosities, online banking presents streamlined business transactions and social media services connect geographically distant people together, to name a few examples, all of which require the seamless sharing of information. Due to the ease of sharing information, many aspects of our lives have become digital. Sensitive personal information, such as personal identification numbers or geographical locations, is now mostly digitised and ``securely" stored in databases, which attract exploiters that seek to intrusively gain access to the valuable information.

Security experts and researchers have been striving to fortify the defence of networks against intrusive security breaches but the society cannot be certain whether it can truly be free of network-based attacks. A constant battle between the experts and exploiters is almost like a game of chess where each move results in a counter-move: new ideas are formulated, realised and outwitted. Invention of revolutionary defensive measures, even if they seem impenetrable at the time of creation, will always run the risk of exposing exploitable vulnerabilities to malicious users. Because of it, a novel security system is highly likely to contribute towards the emergence of novel threats that can be difficult to both capture and react to. Being able to identify and capture novel threats, that the world has never been exposed to, is therefore (1) an important problem that requires our attention and (2) an invaluable asset to security systems if implemented. This thesis is aimed at proposing such a method where novel threats can be detected without any prior knowledge about their intentions and purposes. We propose this thesis in the hope that it will contribute towards improving intervention of novel threats in networks.

In the following sections, the traditional and current methodologies for capturing network-based threats and our motivation are discussed in Section~\ref{intro:sec1}, and the aims and objectives as well as the contributions of this thesis are discussed in Section~\ref{intro:sec2} and \ref{intro:sec3}, respectively.




\section{Motivation}
\label{intro:sec1}
Intrusion detection in networks is the problem of identifying potential exploiters who seek to gain unauthorised access to information. The traditional type of intrusion detection is signature-based where network packets are compared against a database of signatures, or attributes, of known threats recorded by domain experts. A major drawback of signature-based intrusion detection is the inability to detect new threats as the core process of detection depends on the availability of signatures. A threat whose signature is not yet recorded in the database cannot be detected as an intrusion but will rather be incorrectly labelled as a non-threat by definition. This introduces a problem in the field of network intrusion detection where labelled network data are expensive to obtain and seldom available due to their sensitive nature. A solution would be to consider anomaly-based intrusion detection which, depending on situations, does not require labels in data.

The essence of anomaly-based intrusion detection is an application of anomaly detection in network intrusion detection. The idea of anomaly detection is to identify objects that do not conform to other objects in given data. Given a baseline or an expected pattern of normal behaviour, an anomaly is identified if the patterns of the object deviates too much from the baseline as to raise suspicion that it may come from a different distribution than the others. In anomaly-based intrusion detection, these non-conforming objects, or anomalies, are assumed to translate to intrusions and therefore the concept of anomaly detection works well in this domain. Assuming that there are more legitimate users than their intrusive counterparts in a network and the legitimate users behave in a similar way to one another, finding the expected behaviour of the legitimate users is straightforward: simply summarise the major underlying pattern.

There are three types for an anomaly detection task: supervised, semi-supervised and unsupervised. The first two require either fully labelled or partially labelled training data, respectively, in order to build classifiers for unlabelled test data. The third does not require training data therefore there is no training stage. It runs on unlabelled test data directly. The absence of the training stage and requirement for labelled data means that unsupervised anomaly detection is an extremely useful tool as an intrusion detector. It is suitable for the usual situation in the domain where labelling each collection of packets as either good or bad is simply unimaginable considering how large network traffic volumes usually are. It can potentially provide benefits such as (1) saving on resources through reducing, if not preventing, the cost of obtaining labelled data, (2) ability to detect novel threats, which can help further understand any exploitable weaknesses in a network, (3) uncover trends and patterns in attacks and their frequencies to help build better forecast models and (4) help generate labels for unlabelled data, to list only a few.

Despite the many benefits of unsupervised anomaly detection, there exist caveats that require our attention. The unsupervised techniques generally suffer from higher incidences of incorrectly classified normal objects as anomalies, that is False Positives, as they solely rely on comparing the attributes of the objects rather than their actual labels. For the same reason, they can suffer from a lower incidence of correctly classified anomalies, True Positives. The unsupervised anomaly detection techniques are, in a way, double-edged swords capable of detecting novel threats at the cost of the relative underperformance compared to their supervised or semi-supervised counterparts.

<<intro1, fig.pos="h", echo=FALSE, out.width="0.49\\linewidth", fig.show='hold', fig.align='center', fig.cap="Examples of a threshold-based anomaly detection task for arbitrary data.">>=
plot(0, 0, xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2), type="n", asp=1, xlab="", ylab="", axes=FALSE, main = "An arbitrary threshold")
box(asp=1)
set.seed(1); x1 = rnorm(80, sd = 0.5); y1 = rnorm(80, sd=  0.5)
set.seed(1); x2 = rnorm(20, sd = 0.5); y2 = rnorm(20, sd=  0.5)
points(x1, y1, pch = 1, col="blue")
points(x2, y2, pch = 4, cex=1.1, col="red")
xx1 = 1.18*cos( seq(0,2*pi, length.out=360) )
yy1 = 1.18*sin( seq(0,2*pi, length.out=360) )
lines(xx1,yy1)
legend("topright", legend=c("normal","anomaly","threshold"), col = c("blue","red","black"), pch=c(1,4,NA), lty=c(NA,NA,1))

plot(0, 0, xlim = c(-1.2, 1.2), ylim = c(-1.2, 1.2), type="n", asp=1, xlab="", ylab="", axes=FALSE, main = "A permissible version of the arbitrary threshold")
box(asp=1)
points(x1, y1, pch = 1, col="blue")
points(x2, y2, pch = 4, cex=1.1, col="red")
xx2 = 0.76*cos( seq(0,2*pi, length.out=360) )
yx2 = 0.76*sin( seq(0,2*pi, length.out=360) )
lines(xx2,yx2)
legend("topright", legend=c("normal","anomaly","threshold"), col = c("blue","red","black"), pch=c(1,4,NA), lty=c(NA,NA,1))
@

What must also be noted is the relationship between True Positive and False Positive Rates, that is the two rates are positively correlated. Often the unsupervised anomaly detection techniques are threshold-based, which means a change in the threshold, to obtain more True Positives in the result, will induce a respectively increased number of False Positives. To illustrate this point, Figure~\ref{fig:intro1} is presented. In the figure, there are two plots where normal objects and anomalies, from arbitrary data, are represented by the blue circles and red crosses, respectively, and an arbitrary threshold is represented by the solid line. The figure is a simple analogy where objects outside the threshold are to be recognised as possible anomalies, that is including both anomalies (True Positives) and normal (False Positives). If the arbitrary threshold (as seen in the plot on the left from Figure~\ref{fig:intro1}) was to become more permissible (as in the plot on the right from the figure) to allow more anomalies to be recognised, the results of the permissible threshold would include increased numbers for both True Positives and False Positives. This relationship of positive correlation, where an increase in one entity is followed by an increase in another, can be observed in a threshold-based anomaly detection task and is usually presented in a receiver operating characteristic (ROC) curve. An example of an ROC curve is presented in Figure~\ref{fig:intro2}, where the positive relationship can be observed between the True and False Positive Rates.

Many studies in the literature focused on discovering novel approaches to maximise the True Positive Rate while maintaining a low False Positive Rate and presented ROC curves to denote the relationship between the rates, but rarely focused are the rather large numbers of False Positives in the result. Although a giant leap has been made in recent years in the field of unsupervised intrusion detection through various means, there remains an open question as to why focus has not been directed at False Positives themselves and possibly eliminating them to improve results.

<<intro2, fig.pos='h', message=FALSE, echo=FALSE, out.width="0.5\\linewidth", fig.align='center', fig.cap="An example of an ROC curve for arbitrary data">>=
library(pROC)
data(aSAH)
invisible(roc(aSAH$outcome, aSAH$s100b,plot = TRUE, main = "ROC curve", xlab = "False Positive Rate (1 - specificity)", ylab = "True Positive Rate (sensitivity)", legacy.axes = TRUE))
@



\section{Aims and objectives}
\label{intro:sec2}
Our goal of this thesis is to present a novel unsupervised anomaly-based network intrusion detection framework. The novelty in our method comes from the way it addresses the previously mentioned problem faced by most unsupervised learning tasks. A high-level system overview is summarised as a flowchart in Figure~\ref{fig:intro} to supplement the following description of our proposed approach. Our method is divided into two phases. In Phase~1, each instance in given test data is robustly scored using the density-based anomaly scoring algorithm, LOF, and is identified as either a possible anomaly or normal using a relaxed threshold based on the distribution of the computed scores, and a random sample of the normal instances is merged with the possible anomalies as output. The use of the relaxed threshold permits more potential anomalies to be identified as the objects can more easily surpass the required threshold. In Phase~2, the density-based clustering algorithm, DBSCAN, is run on the previously mentioned merged data and the clusters of False Positives are produced with the help of the normal instances, which are then removed from the result. We carry out experiments on our method to evaluate (1) whether Phase~1 is capable of achieving a high True Positive Rate and the extent of False Positives produced along with its accuracy and precision, (2) the degree of False Positives eliminated by Phase~2 in percentage reduction and (3) overall detection power, accuracy and precision. We compare our result with other approaches to highlight advantages as well as disadvantages of using respective methods. The method we propose does not rely on signatures, training or labelled data but rather it is robust through the use of local density-based approaches that can achieve highly accurate and precise detection. The main advantage of our method is in the relatively low rate of False Positives in the result, making it a tool that can be used to label potential threats in a network to help further analysis. In addition, our method performs well in the presence of multiple types of attacks.

\begin{figure}
\centering
  \begin{tikzpicture}[node distance = 2.3cm, scale=0.8]
    \node(start) [start] {\textsc{Start}};
    \node(in)    [io, below of=start]  {Data \\ (numeric)};
    \node(p1)    [procs, below of=in, minimum width=6.5cm]  {Phase 1: \\ Density-based anomaly detection};
    \node(pa)    [io, below of=p1]     {Possible \\ intrusions};
    \node(p2)    [procs, below of=pa, minimum width=6.5cm]  {Phase 2: \\ Clustering-based FP removal};
    \node(out)   [io, below of=p2]     {Intrusions};
    \node(end)   [start, below of=out] {\textsc{End}};
    \draw [arrow] (start) to (in);
    \draw [arrow] (in) to (p1);
    \draw [arrow] (p1) to (pa);
    \draw [arrow] (pa) to (p2);
    \draw [arrow] (p2) to (out);
    \draw [arrow] (out) to (end);
  \end{tikzpicture}
  \caption{A high-level system overview of our proposed method for intrusion detection in networks.}
  \label{fig:intro}
\end{figure}

\section{Contribution}
\label{intro:sec3}
If more and more aspects of the society are to lean towards digitalisation and highly facilitated exchange and circulation of digitised information between individuals, we must direct our attention to protect valuable information from unauthorised access. And the first step to greet such a future is being able to identify these threats, to which we present the work described in the following chapters. The main contributions of this thesis are: first, we explore the implications of reducing the number of False Positives in the results and how our method to reduce False Positive is implemented and second, we propose a novel two-phase intrusion detector in networks, which is both density- and anomaly-based as well as unsupervised.












% The core mechanism of anomaly detection does not depend on data labels but rather appropriate attributes of individual objects. Usually a similarity metric, such as Euclidean distance, is computed and compared for each object to assess relative similarity between one another. This allows for the task of anomaly detection to be executed under the three types of machine learning: supervised, semi-supervised and unsupervised.

% However, as with many revolutionary inventions, the other side of the coin exists in the forms of social, physical and developmental problems which every user should be aware of, or at least consider.





% An anomaly, also known as an \emph{outlier} in the field of statistics, is defined by Hawkins \cite{haw80} to be
% \begin{quote}
% an observation which deviates so much from other observations as to arouse suspicions that it was generated by a different mechanism.
% \end{quote}
% 
% Anomalies are of a particular interest as they generally translate to something bad (eg, malicious attack, bank fraud)





% Discuss (1) signature- vs. anomaly-based NIDS  and (2) supervised vs. unsupervised A-NIDS.
% The gap in the knowledge: most systems require training stages but training data are not easily obtainable/available. Also many systems focus only on finding anomalies using unsupervised algorithms but rarely focus on resulting false positives.
% Our goal is to implement an \emph{unsupervised} anomaly-based network intrusion detection
% 
% 
% 
% 
% 
% 
% 
% The particular nature of input data in network intrusion detection is that of a mixed type, that is it consists of numeric, binary and categorical features.
% 
% Also, it is not a spatial data, where each instance is given positional information, nor a graph data, where each instance is represented as a vertex or a node.
% 
% 
% \neapge
% An intrusion detection system (IDS) can fall under two main categories: a signature-based and an anomaly-based IDS where the former detects threats by matching connections with a database of previously known hostile connections and the latter by treating the threats as anomalies. In comparison to the anomaly-based IDS, the signature-based IDS is associated with superior performance through higher detection rate with minimal false alarm rate in a similar manner
% 
% 
% The domain of unsupervised anomaly detection is, in particular, attractive to the field of network intrusion detection due to its ability to detect novel hostile connections.
% 
% 
% has attracted much attention due to its ability to detect novel attacks which
% 
% There are 
% 
% The intrusion detection scheme that we propose is a two-phase method that falls within the domain of unsupervised anomaly detection. 

%Our aim is to detect hostile connections within a network with minimal false alarm occurrence through an unsupervised anomaly detection technique. As introduced in Chapter [REF intro], the domain of unsupervised anomaly detection is, especially, attractive to the field of network intrusion detection as it allows the possibility of detecting novel threats without a need for attack labels. The most crucial aspect of securing a network or a system is probably in the ability to prevent further losses from the attacks of previously known characteristics. What is of an equal, or possibly greater, importance is the ability to identify previously unknown threats before any harm is inflicted. As with any forms of crime, new trends of cyber-crime are constantly emerging for a need to fortify networks and systems with the intelligence to cope with any possible novelty. This has given us a sounding reason to pursue the idea of implementing an unsupervised approach into our method.

%Supervised and semi-supervised anomaly detection techniques are not considered in our method as they require a labelled training dataset from which a classifier or a model is constructed. Since the desired outcome of this research is a network intrusion detection system (NIDS) with the novelty detection capability, any labels in a dataset are treated as non-existent and are only used for system evaluation.



% Comment below out when building the whole doc:
% \bibliographystyle{ieeetr}
% \bibliography{../Main/bibliography}
